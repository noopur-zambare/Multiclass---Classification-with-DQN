{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRHO4f0SDeVo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5YWKkRozMe-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Financial Distress.csv')\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X = df[['Company', 'Time', 'x1', 'x2', 'x3', 'x4']]\n",
        "df['Label - Financial Distress'] = pd.cut(df['Financial Distress'], bins=[-float('inf'), 10,28,45,63,80,96,111,float('inf')], labels=[0,1, 2, 3, 4, 5, 6, 7], right=False)\n",
        "y = df['Label - Financial Distress']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "X['Company'] = label_encoder.fit_transform(df['Company'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "gamma = 0.95\n",
        "epsilon = 1.0\n",
        "episodes = 200\n",
        "\n",
        "# Create unique integer labels for each action\n",
        "action_size = len(np.unique(y))\n",
        "action_labels = np.arange(action_size)\n",
        "\n",
        "\n",
        "# Train and evaluate the combined DQN model\n",
        "state_size = X.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piiFCLibzGgu"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYVkXBKGNN2w"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the base decision tree model\n",
        "base_model = DecisionTreeClassifier()\n",
        "base_model.fit(X_train, y_train)\n",
        "base_accuracy_dt = round(base_model.score(X_test, y_test), 2)\n",
        "print(\"Base Model Accuracy: {:.2f}\".format(base_accuracy_dt))\n",
        "base_recall_dt = round(recall_score(y_test, base_model.predict(X_test), average='macro'),2)\n",
        "base_precision_dt = round(precision_score(y_test, base_model.predict(X_test), average='macro'),2)\n",
        "print(\"Base Model Recall:\", base_recall_dt)\n",
        "print(\"Base Model Precision:\", base_precision_dt)\n",
        "\n",
        "class DQN:\n",
        "    def __init__(self, state_size, action_size, learning_rate, gamma, epsilon):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        # Build the Q-network (ensemble of decision trees)\n",
        "        self.model = [DecisionTreeClassifier() for _ in range(self.action_size)]\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        pass  # Not needed for decision tree-based approach\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        else:\n",
        "            q_values = [model.predict_proba(state.reshape(1, -1)) for model in self.model]\n",
        "            return np.argmax(q_values)\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        pass  # Not needed for decision tree-based approach\n",
        "\n",
        "    def train(self, X, y, episodes, epochs):\n",
        "        for episode in range(episodes):\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "\n",
        "            for state in X:\n",
        "                while not done:\n",
        "                    action = self.act(state)\n",
        "                    reward = 1 if (action_labels[action] == y.values).any() else -1\n",
        "\n",
        "                    total_reward += reward\n",
        "                    done = True\n",
        "\n",
        "                    for _ in range(epochs):\n",
        "                        self.model[action].fit([state], [action_labels[action]])\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.zeros((len(X), self.action_size))\n",
        "        for i, state in enumerate(X):\n",
        "            action = self.act(state)\n",
        "            y_pred[i, action] = 1\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "dqn_agent = DQN(state_size, action_size, learning_rate, gamma, epsilon)\n",
        "dqn_agent.train(X_train.values, y_train, episodes, 3)\n",
        "dqn_accuracy_dt = round(np.mean(np.argmax(dqn_agent.predict(X_test.values), axis=1) == y_test), 2)\n",
        "print(\"DQN Accuracy: {:.2f}\".format(dqn_accuracy_dt))\n",
        "dqn_recall_dt = round(recall_score(y_test, np.argmax(dqn_agent.predict(X_test.values), axis=1), average='macro'),2)\n",
        "dqn_precision_dt = round(precision_score(y_test, np.argmax(dqn_agent.predict(X_test.values), axis=1), average='macro'),2)\n",
        "print(\"DQN Model Recall:\", dqn_recall_dt)\n",
        "print(\"DQN Model Precision:\", dqn_precision_dt)\n",
        "\n",
        "\n",
        "# varying epochs\n",
        "epochs = []\n",
        "dqn_list = []\n",
        "for i in range(1,10):\n",
        "  epochs.append(i)\n",
        "  dqn_agent.train(X_train.values, y_train, episodes, i)\n",
        "  dqn_list.append(round(np.mean(np.argmax(dqn_agent.predict(X_test.values), axis=1) == y_test), 2))\n",
        "\n",
        "plt.plot(epochs,dqn_list, color = '#65cbe9')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Variation of Accuracy with Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDt570W0PU93"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi8t1Qe7PWvb"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the base random forest model\n",
        "base_model = RandomForestClassifier()\n",
        "base_model.fit(X_train, y_train)\n",
        "base_accuracy_rf = round(base_model.score(X_test, y_test),2)\n",
        "print(\"Base Model Accuracy: {:.2f}\".format(base_accuracy_rf))\n",
        "base_recall_rf = round(recall_score(y_test, base_model.predict(X_test), average='macro'),2)\n",
        "base_precision_rf = round(precision_score(y_test, base_model.predict(X_test), average='macro'),2)\n",
        "print(\"Base Model Recall:\", base_recall_rf)\n",
        "print(\"Base Model Precision:\", base_precision_rf)\n",
        "\n",
        "\n",
        "\n",
        "class DQN:\n",
        "    def __init__(self, state_size, action_size, learning_rate, gamma, epsilon):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        # Build the Q-network (ensemble of random forest classifiers)\n",
        "        self.model = [RandomForestClassifier() for _ in range(self.action_size)]\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        pass\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        else:\n",
        "            q_values = [model.predict_proba(state.reshape(1, -1)) for model in self.model]\n",
        "            return np.argmax(q_values)\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        pass\n",
        "\n",
        "    def train(self, X, y, episodes, epochs):\n",
        "        for episode in range(episodes):\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "\n",
        "            for state in X:\n",
        "                while not done:\n",
        "                    action = self.act(state)\n",
        "                    reward = 1 if (action_labels[action] == y.values).any() else -1\n",
        "\n",
        "                    total_reward += reward\n",
        "                    done = True\n",
        "\n",
        "                    for _ in range(epochs):\n",
        "                        self.model[action].fit([state], [action_labels[action]])\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.zeros((len(X), self.action_size))\n",
        "        for i, state in enumerate(X):\n",
        "            action = self.act(state)\n",
        "            y_pred[i, action] = 1\n",
        "        return y_pred\n",
        "\n",
        "dqn_agent = DQN(state_size, action_size, learning_rate, gamma, epsilon)\n",
        "dqn_agent.train(X_train.values, y_train, episodes, 1)\n",
        "dqn_accuracy_rf = round(np.mean(np.argmax(dqn_agent.predict(X_test.values), axis=1) == y_test),2)\n",
        "print(\"DQN Accuracy: {:.2f}\".format(dqn_accuracy_rf))\n",
        "dqn_recall_rf = round(recall_score(y_test, np.argmax(dqn_agent.predict(X_test.values), axis=1), average='macro'),2)\n",
        "dqn_precision_rf = round(precision_score(y_test, np.argmax(dqn_agent.predict(X_test.values), axis=1), average='macro'),2)\n",
        "print(\"DQN Model Recall:\", dqn_recall_rf)\n",
        "print(\"DQN Model Precision:\", dqn_precision_rf)\n",
        "\n",
        "\n",
        "# varying epochs\n",
        "epochs = []\n",
        "dqn_list = []\n",
        "for i in range(1,10):\n",
        "  epochs.append(i)\n",
        "  dqn_agent.train(X_train.values, y_train, episodes, i)\n",
        "  dqn_list.append(round(np.mean(np.argmax(dqn_agent.predict(X_test.values), axis=1) == y_test), 2))\n",
        "\n",
        "plt.plot(epochs,dqn_list, color = '#65cbe9')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Variation of Accuracy with Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFSojsTS_Dzn"
      },
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6Z7-GvX_GQH"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the base Naive Bayes model\n",
        "base_model = GaussianNB()\n",
        "base_model.fit(X_train, y_train)\n",
        "base_accuracy_nb = round(base_model.score(X_test, y_test),2)\n",
        "print(\"Base Model Accuracy: {:.2f}\".format(base_accuracy_nb))\n",
        "base_recall_nb = round(recall_score(y_test, base_model.predict(X_test), average='macro'),2)\n",
        "base_precision_nb = round(precision_score(y_test, base_model.predict(X_test), average='macro'),2)\n",
        "print(\"Base Model Recall:\", base_recall_nb)\n",
        "print(\"Base Model Precision:\", base_precision_nb)\n",
        "\n",
        "\n",
        "class DQN:\n",
        "    def __init__(self, state_size, action_size, learning_rate, gamma, epsilon):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        # Build the Q-network (ensemble of Naive Bayes models)\n",
        "        self.model = [GaussianNB() for _ in range(self.action_size)]\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        pass\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        else:\n",
        "            q_values = [model.predict_proba([state])[0] for model in self.model]\n",
        "            return np.argmax(q_values)\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        pass\n",
        "\n",
        "    def train(self, X, y, episodes, epochs):\n",
        "        for episode in range(episodes):\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "\n",
        "            for state in X:\n",
        "                while not done:\n",
        "                    action = self.act(state)\n",
        "                    reward = 1 if (action_labels[action] == y.values).any() else -1\n",
        "\n",
        "                    total_reward += reward\n",
        "                    done = True\n",
        "\n",
        "                    for _ in range(epochs):\n",
        "                        self.model[action].fit([state], [action_labels[action]])\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.zeros((len(X), self.action_size))\n",
        "        for i, state in enumerate(X):\n",
        "            action = self.act(state)\n",
        "            y_pred[i, action] = 1\n",
        "        return y_pred\n",
        "\n",
        "dqn_agent = DQN(state_size, action_size, learning_rate, gamma, epsilon)\n",
        "dqn_agent.train(X_train.values, y_train, episodes, 10)\n",
        "dqn_accuracy_nb = round(np.mean(np.argmax(dqn_agent.predict(X_test.values), axis=1) == y_test),2)\n",
        "print(\"DQN Accuracy: {:.2f}\".format(dqn_accuracy_nb))\n",
        "dqn_recall_nb = round(recall_score(y_test, np.argmax(dqn_agent.predict(X_test.values), axis=1), average='macro'),2)\n",
        "dqn_precision_nb = round(precision_score(y_test, np.argmax(dqn_agent.predict(X_test.values), axis=1), average='macro'),2)\n",
        "print(\"DQN Model Recall:\", dqn_recall_nb)\n",
        "print(\"DQN Model Precision:\", dqn_precision_nb)\n",
        "\n",
        "\n",
        "# varying epochs\n",
        "epochs = []\n",
        "dqn_list = []\n",
        "for i in range(1,10):\n",
        "  epochs.append(i)\n",
        "  dqn_agent.train(X_train.values, y_train, episodes, i)\n",
        "  dqn_list.append(round(np.mean(np.argmax(dqn_agent.predict(X_test.values), axis=1) == y_test), 2))\n",
        "\n",
        "plt.plot(epochs,dqn_list, color = '#65cbe9')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Variation of Accuracy with Epochs')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "mql2YVB_7VzJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oN-iEOFHD__"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "algo = (\"Decision Tree\", \"Random Forest Classifier\", \"Naive Bayes\")\n",
        "models = {\n",
        "    'Base Model': (base_accuracy_dt, base_accuracy_rf, base_accuracy_nb),\n",
        "    'Model with DQN' : (dqn_accuracy_dt, dqn_accuracy_rf, dqn_accuracy_nb),\n",
        "}\n",
        "\n",
        "x = np.arange(len(algo))\n",
        "width = 0.25\n",
        "multiplier = 0\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "colors = ['#AFD5F0', '#D4FAFA']\n",
        "\n",
        "for attribute, measurement in models.items():\n",
        "    offset = width * multiplier\n",
        "    rects = ax.bar(x + offset, measurement, width, label=attribute, color=colors[multiplier])\n",
        "    ax.bar_label(rects, padding=3)\n",
        "    multiplier += 1\n",
        "\n",
        "ax.set_ylabel('Validation Accuracy')\n",
        "ax.set_title('Comparison for various models')\n",
        "ax.set_xticks(x + width, algo)\n",
        "ax.legend(loc='upper left', ncols=3)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}